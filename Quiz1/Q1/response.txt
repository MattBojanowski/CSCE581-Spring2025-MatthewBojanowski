I used a logistic regression classifier and a random forest classifier to check the data. The results were printed to a file called output.txt. I tested and checked for bias in 4 different ways. Models 1 and 2 both checked on the data, but used "class_weight='balanced'" to evenly distribute class weight on the "biased" data. Models 3 and 4 did not use balanced class weight, and used the "biased" data. Then, I made code which attempts to remove the bias of race, sex, and age_cat. Models 5 and 6 used "class_weight='balanced'" with the unbiased data. Finally, models 7 and 8 didn't use balanced class weight and used unbiased data. After the program ran, I noticed that all models using my modified "unbiased" data were less accurate, and stayed around 62%-63% accuracy, while the models with the "biased" data had higher accuracy on average. Overall, models 3 and 4 (using unbalanced class weight and the biased data) were the most accurate, so I think those models work the best to guess for repeat offenders in the future.