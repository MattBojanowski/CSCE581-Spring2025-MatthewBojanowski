{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3519e64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                name   first         last compas_screening_date   sex  \\\n",
      "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
      "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
      "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
      "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
      "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
      "\n",
      "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
      "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
      "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
      "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
      "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
      "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
      "\n",
      "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
      "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
      "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
      "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
      "3        Medium        2013-01-13         NaN          NaN               1   \n",
      "4           Low        2013-03-26         NaN          NaN               2   \n",
      "\n",
      "  start   end event two_year_recid  \n",
      "0     0   327     0              0  \n",
      "1     9   159     1              1  \n",
      "2     0    63     0              1  \n",
      "3     0  1174     0              0  \n",
      "4     0  1102     0              0  \n",
      "\n",
      "[5 rows x 53 columns]\n",
      "id\n",
      "name\n",
      "first\n",
      "last\n",
      "compas_screening_date\n",
      "sex\n",
      "dob\n",
      "age\n",
      "age_cat\n",
      "race\n",
      "juv_fel_count\n",
      "decile_score\n",
      "juv_misd_count\n",
      "juv_other_count\n",
      "priors_count\n",
      "days_b_screening_arrest\n",
      "c_jail_in\n",
      "c_jail_out\n",
      "c_case_number\n",
      "c_offense_date\n",
      "c_arrest_date\n",
      "c_days_from_compas\n",
      "c_charge_degree\n",
      "c_charge_desc\n",
      "is_recid\n",
      "r_case_number\n",
      "r_charge_degree\n",
      "r_days_from_arrest\n",
      "r_offense_date\n",
      "r_charge_desc\n",
      "r_jail_in\n",
      "r_jail_out\n",
      "violent_recid\n",
      "is_violent_recid\n",
      "vr_case_number\n",
      "vr_charge_degree\n",
      "vr_offense_date\n",
      "vr_charge_desc\n",
      "type_of_assessment\n",
      "decile_score\n",
      "score_text\n",
      "screening_date\n",
      "v_type_of_assessment\n",
      "v_decile_score\n",
      "v_score_text\n",
      "v_screening_date\n",
      "in_custody\n",
      "out_custody\n",
      "priors_count\n",
      "start\n",
      "end\n",
      "event\n",
      "two_year_recid\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7214 entries, 0 to 7213\n",
      "Data columns (total 53 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       7214 non-null   int64  \n",
      " 1   name                     7214 non-null   object \n",
      " 2   first                    7214 non-null   object \n",
      " 3   last                     7214 non-null   object \n",
      " 4   compas_screening_date    7214 non-null   object \n",
      " 5   sex                      7214 non-null   object \n",
      " 6   dob                      7214 non-null   object \n",
      " 7   age                      7214 non-null   int64  \n",
      " 8   age_cat                  7214 non-null   object \n",
      " 9   race                     7214 non-null   object \n",
      " 10  juv_fel_count            7214 non-null   int64  \n",
      " 11  decile_score             7214 non-null   int64  \n",
      " 12  juv_misd_count           7214 non-null   int64  \n",
      " 13  juv_other_count          7214 non-null   int64  \n",
      " 14  priors_count             7214 non-null   int64  \n",
      " 15  days_b_screening_arrest  6907 non-null   float64\n",
      " 16  c_jail_in                6907 non-null   object \n",
      " 17  c_jail_out               6907 non-null   object \n",
      " 18  c_case_number            7192 non-null   object \n",
      " 19  c_offense_date           6055 non-null   object \n",
      " 20  c_arrest_date            1137 non-null   object \n",
      " 21  c_days_from_compas       7192 non-null   float64\n",
      " 22  c_charge_degree          7214 non-null   object \n",
      " 23  c_charge_desc            7185 non-null   object \n",
      " 24  is_recid                 7214 non-null   int64  \n",
      " 25  r_case_number            3471 non-null   object \n",
      " 26  r_charge_degree          3471 non-null   object \n",
      " 27  r_days_from_arrest       2316 non-null   float64\n",
      " 28  r_offense_date           3471 non-null   object \n",
      " 29  r_charge_desc            3413 non-null   object \n",
      " 30  r_jail_in                2316 non-null   object \n",
      " 31  r_jail_out               2316 non-null   object \n",
      " 32  violent_recid            0 non-null      float64\n",
      " 33  is_violent_recid         7214 non-null   int64  \n",
      " 34  vr_case_number           819 non-null    object \n",
      " 35  vr_charge_degree         819 non-null    object \n",
      " 36  vr_offense_date          819 non-null    object \n",
      " 37  vr_charge_desc           819 non-null    object \n",
      " 38  type_of_assessment       7214 non-null   object \n",
      " 39  decile_score.1           7214 non-null   int64  \n",
      " 40  score_text               7214 non-null   object \n",
      " 41  screening_date           7214 non-null   object \n",
      " 42  v_type_of_assessment     7214 non-null   object \n",
      " 43  v_decile_score           7214 non-null   int64  \n",
      " 44  v_score_text             7214 non-null   object \n",
      " 45  v_screening_date         7214 non-null   object \n",
      " 46  in_custody               6978 non-null   object \n",
      " 47  out_custody              6978 non-null   object \n",
      " 48  priors_count.1           7214 non-null   int64  \n",
      " 49  start                    7214 non-null   int64  \n",
      " 50  end                      7214 non-null   int64  \n",
      " 51  event                    7214 non-null   int64  \n",
      " 52  two_year_recid           7214 non-null   int64  \n",
      "dtypes: float64(4), int64(16), object(33)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from collections import defaultdict\n",
    "import urllib\n",
    "import os,sys\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# find the csv file\n",
    "csv_file = 'compas-scores-two-years.csv'\n",
    "# read the file into a data frame\n",
    "df = pd.read_csv(csv_file, engine='python', on_bad_lines='skip')\n",
    "print(df.head())\n",
    "with open(csv_file, \"r\") as f:\n",
    "    first_line = f.readline().strip()\n",
    "# view some of the data\n",
    "parts = first_line.split(\",\")\n",
    "for part in parts: \n",
    "    print(part)\n",
    "df.info()\n",
    "df.describe(include='all').transpose()\n",
    "\n",
    "# make copy of data for later\n",
    "df_copy = pd.read_csv(csv_file, engine='python', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9a12c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of people recidivating within two years\n",
      "-1    3963\n",
      " 1    3251\n",
      "Name: count, dtype: int64\n",
      "{'race': array([0, 0, 0, ..., 1, 0, 0], shape=(43284,))}\n",
      "(7214, 12)\n",
      "(7214,)\n",
      "['age_cat_25 - 45', 'age_cat_Greater than 45', 'age_cat_Less than 25', 'race_African-American', 'race_Asian', 'race_Caucasian', 'race_Hispanic', 'race_Native American', 'race_Other', 'sex', 'priors_count', 'c_charge_degree']\n"
     ]
    }
   ],
   "source": [
    "FEATURES_CLASS = [\"age_cat\", \"race\", \"sex\", \"priors_count\", \"c_charge_degree\"]\n",
    "CONTI_FEATURE = [\"priors_count\"]\n",
    "CLASS_FEATURE = \"two_year_recid\"\n",
    "SENSITIVE_FEATURE = \"race\"\n",
    "data = df.to_dict('list')\n",
    "for k in data.keys():\n",
    "\tdata[k] = np.array(data[k])\n",
    "y = data[CLASS_FEATURE]\n",
    "y[y==0] = -1\n",
    "\n",
    "\n",
    "print (\"\\nNumber of people recidivating within two years\")\n",
    "print (pd.Series(y).value_counts())\n",
    "X = np.array([]).reshape(len(y), 0)\n",
    "x_control = defaultdict(list)\n",
    "feature_names = []\n",
    "\n",
    "for attr in FEATURES_CLASS:\n",
    "\t\tvals = data[attr]\n",
    "\t\tif attr in CONTI_FEATURE:\n",
    "\t\t\tvals = [float(v) for v in vals]\n",
    "\t\t\tvals = preprocessing.scale(vals) # 0 mean and 1 variance  \n",
    "\t\t\tvals = np.reshape(vals, (len(y), -1)) # convert from 1-d arr to a 2-d arr with one col\n",
    "\n",
    "\t\telse: # for binary categorical variables, the label binarizer uses just one var instead of two\n",
    "\t\t\tlb = preprocessing.LabelBinarizer()\n",
    "\t\t\tlb.fit(vals)\n",
    "\t\t\tvals = lb.transform(vals)\n",
    "\n",
    "\t\t# add to sensitive features dict\n",
    "\t\tif attr in SENSITIVE_FEATURE:\n",
    "\t\t\tx_control[attr] = vals\n",
    "\n",
    "\n",
    "\t\t# add to learnable features\n",
    "\t\tX = np.hstack((X, vals))\n",
    "\n",
    "\t\tif attr in CONTI_FEATURE: # continuous feature, just append the name\n",
    "\t\t\tfeature_names.append(attr)\n",
    "\t\telse: # categorical features\n",
    "\t\t\tif vals.shape[1] == 1: # binary features that passed through lib binarizer\n",
    "\t\t\t\tfeature_names.append(attr)\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor k in lb.classes_: # non-binary categorical features, need to add the names for each cat\n",
    "\t\t\t\t\tfeature_names.append(attr + \"_\" + str(k))\n",
    "\n",
    "\n",
    "# convert the sensitive feature to 1-d array\n",
    "x_control = dict(x_control)\n",
    "for k in x_control.keys():\n",
    "\t\tx_control[k] = np.array(x_control[k]).flatten()\n",
    "\t\n",
    "print(x_control)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c28d7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_split_into_train_test(x_all, y_all, x_control_all, train_size):\n",
    "\n",
    "    split_point = int(round(float(x_all.shape[0]) * train_size))\n",
    "    x_all_train = x_all[:split_point]\n",
    "    x_all_test = x_all[split_point:]\n",
    "    y_all_train = y_all[:split_point]\n",
    "    y_all_test = y_all[split_point:]\n",
    "    x_control_all_train = {}\n",
    "    x_control_all_test = {}\n",
    "    for k in x_control_all.keys():\n",
    "        x_control_all_train[k] = x_control_all[k][:split_point]\n",
    "        x_control_all_test[k] = x_control_all[k][split_point:]\n",
    "\n",
    "    return x_all_train, y_all_train, x_control_all_train, x_all_test, y_all_test, x_control_all_test\n",
    "def my_split (x_all,y_all,train_size):\n",
    "  split_point = int(round(float(x_all.shape[0]) * train_size))\n",
    "  x_all_train = x_all[:split_point]\n",
    "  x_all_test = x_all[split_point:]\n",
    "  y_all_train = y_all[:split_point]\n",
    "  y_all_test = y_all[split_point:]\n",
    "\n",
    "  return x_all_train, y_all_train, x_all_test, y_all_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "x_train, y_train, x_test, y_test = my_split(X,y,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d05c78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6570784959279155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.67      0.68      3151\n",
      "           1       0.62      0.64      0.63      2620\n",
      "\n",
      "    accuracy                           0.66      5771\n",
      "   macro avg       0.65      0.66      0.65      5771\n",
      "weighted avg       0.66      0.66      0.66      5771\n",
      "\n",
      "[0.67428967 0.66389466 0.64449064 0.67567568 0.65950069]\n"
     ]
    }
   ],
   "source": [
    "# train model 1 on balanced weights\n",
    "model1 = LogisticRegression(class_weight='balanced')\n",
    "model1.fit(x_train, y_train)\n",
    "y_pred = model1.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "model1accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "model1report = classification_report(y_test, y_pred)\n",
    "scores1 = cross_val_score(model1, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eaf8230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.628140703517588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.69      0.67      3151\n",
      "           1       0.60      0.56      0.58      2620\n",
      "\n",
      "    accuracy                           0.63      5771\n",
      "   macro avg       0.62      0.62      0.62      5771\n",
      "weighted avg       0.63      0.63      0.63      5771\n",
      "\n",
      "[0.66112266 0.65003465 0.63063063 0.66181566 0.64840499]\n"
     ]
    }
   ],
   "source": [
    "# train model 2 on balanced weights\n",
    "model2 = RandomForestClassifier(class_weight='balanced')\n",
    "model2.fit(x_train, y_train)\n",
    "y_pred = model2.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "model2accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "model2report = classification_report(y_test, y_pred)\n",
    "scores2 = cross_val_score(model2, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b66221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.660370819615318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.78      0.71      3151\n",
      "           1       0.66      0.52      0.58      2620\n",
      "\n",
      "    accuracy                           0.66      5771\n",
      "   macro avg       0.66      0.65      0.65      5771\n",
      "weighted avg       0.66      0.66      0.65      5771\n",
      "\n",
      "[0.67706168 0.66597367 0.65003465 0.67636868 0.65603329]\n"
     ]
    }
   ],
   "source": [
    "# re-train model 1 on normal weights\n",
    "model3 = LogisticRegression()\n",
    "model3.fit(x_train, y_train)\n",
    "y_pred = model3.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "model3accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "model3report = classification_report(y_test, y_pred)\n",
    "scores3 = cross_val_score(model3, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(scores3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f1f340c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6357650320568359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.71      0.68      3151\n",
      "           1       0.61      0.54      0.58      2620\n",
      "\n",
      "    accuracy                           0.64      5771\n",
      "   macro avg       0.63      0.63      0.63      5771\n",
      "weighted avg       0.63      0.64      0.63      5771\n",
      "\n",
      "[0.66042966 0.65349965 0.63201663 0.64795565 0.65464632]\n"
     ]
    }
   ],
   "source": [
    "# re-train model 2 on normal weights\n",
    "model4 = RandomForestClassifier()\n",
    "model4.fit(x_train, y_train)\n",
    "y_pred = model4.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "model4accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "model4report = classification_report(y_test, y_pred)\n",
    "scores4 = cross_val_score(model4, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(scores4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ce5ab4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of people recidivating within two years\n",
      "-1    3963\n",
      " 1    3251\n",
      "Name: count, dtype: int64\n",
      "{}\n",
      "(7214, 2)\n",
      "(7214,)\n",
      "['priors_count', 'priors_count', 'c_charge_degree', 'c_charge_degree']\n"
     ]
    }
   ],
   "source": [
    "# re-train both models after removing possible sensitive info for less bias\n",
    "FEATURES_CLASS = [\"priors_count\", \"c_charge_degree\"]\n",
    "CONTI_FEATURE = [\"priors_count\"]\n",
    "CLASS_FEATURE = \"two_year_recid\"\n",
    "SENSITIVE_FEATURE = \"race\"\n",
    "data = df_copy.to_dict('list')\n",
    "for k in data.keys():\n",
    "\tdata[k] = np.array(data[k])\n",
    "y = data[CLASS_FEATURE]\n",
    "y[y==0] = -1\n",
    "\n",
    "\n",
    "print (\"\\nNumber of people recidivating within two years\")\n",
    "print (pd.Series(y).value_counts())\n",
    "X = np.array([]).reshape(len(y), 0)\n",
    "x_control = defaultdict(list)\n",
    "feature_names = []\n",
    "\n",
    "for attr in FEATURES_CLASS:\n",
    "\tvals = data[attr]\n",
    "\tif attr in CONTI_FEATURE:\n",
    "\t\tvals = vals.astype(float)\n",
    "\t\tvals = preprocessing.scale(vals).reshape(len(y), -1)\n",
    "\t\tfeature_names.append(attr)\n",
    "\telse:\n",
    "\t\tlb = preprocessing.LabelBinarizer()\n",
    "\t\tlb.fit(vals)\n",
    "\t\tvals = lb.transform(vals)\n",
    "\t\tif vals.shape[1] == 1:\n",
    "\t\t\tfeature_names.append(attr)\n",
    "\t\telse:\n",
    "\t\t\tfor k in lb.classes_:\n",
    "\t\t\t\tfeature_names.append(f\"{attr}_{k}\")\n",
    "\tX = np.hstack((X, vals))\n",
    "\t\n",
    "\tif attr in CONTI_FEATURE: # continuous feature, just append the name\n",
    "\t\tfeature_names.append(attr)\n",
    "\telse: # categorical features\n",
    "\t\tif vals.shape[1] == 1: # binary features that passed through lib binarizer\n",
    "\t\t\tfeature_names.append(attr)\n",
    "\t\telse:\n",
    "\t\t\tfor k in lb.classes_: # non-binary categorical features, need to add the names for each cat\n",
    "\t\t\t\tfeature_names.append(attr + \"_\" + str(k))\n",
    "\n",
    "\n",
    "# convert the sensitive feature to 1-d array\n",
    "x_control = dict(x_control)\n",
    "for k in x_control.keys():\n",
    "\t\tx_control[k] = np.array(x_control[k]).flatten()\n",
    "\t\n",
    "print(x_control)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(feature_names)\n",
    "def my_split_into_train_test(x_all, y_all, x_control_all, train_size):\n",
    "\n",
    "    split_point = int(round(float(x_all.shape[0]) * train_size))\n",
    "    x_all_train = x_all[:split_point]\n",
    "    x_all_test = x_all[split_point:]\n",
    "    y_all_train = y_all[:split_point]\n",
    "    y_all_test = y_all[split_point:]\n",
    "    x_control_all_train = {}\n",
    "    x_control_all_test = {}\n",
    "    for k in x_control_all.keys():\n",
    "        x_control_all_train[k] = x_control_all[k][:split_point]\n",
    "        x_control_all_test[k] = x_control_all[k][split_point:]\n",
    "\n",
    "    return x_all_train, y_all_train, x_control_all_train, x_all_test, y_all_test, x_control_all_test\n",
    "def my_split (x_all,y_all,train_size):\n",
    "  split_point = int(round(float(x_all.shape[0]) * train_size))\n",
    "  x_all_train = x_all[:split_point]\n",
    "  x_all_test = x_all[split_point:]\n",
    "  y_all_train = y_all[:split_point]\n",
    "  y_all_test = y_all[split_point:]\n",
    "\n",
    "  return x_all_train, y_all_train, x_all_test, y_all_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "x_train, y_train, x_test, y_test = my_split(X,y,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78641af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6394039161323861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.77      0.70      3151\n",
      "           1       0.63      0.49      0.55      2620\n",
      "\n",
      "    accuracy                           0.64      5771\n",
      "   macro avg       0.64      0.63      0.62      5771\n",
      "weighted avg       0.64      0.64      0.63      5771\n",
      "\n",
      "[0.65349965 0.64033264 0.60776161 0.66250866 0.64909847]\n"
     ]
    }
   ],
   "source": [
    "# re-train model 1 on balanced weights and \"unbiased\" data\n",
    "model5 = LogisticRegression(class_weight='balanced')\n",
    "model5.fit(x_train, y_train)\n",
    "y_pred = model5.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "model5accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "model5report = classification_report(y_test, y_pred)\n",
    "scores5 = cross_val_score(model5, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(scores5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0efd6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6340322301160978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.76      0.69      3151\n",
      "           1       0.62      0.49      0.55      2620\n",
      "\n",
      "    accuracy                           0.63      5771\n",
      "   macro avg       0.63      0.62      0.62      5771\n",
      "weighted avg       0.63      0.63      0.63      5771\n",
      "\n",
      "[0.63825364 0.62924463 0.60637561 0.64795565 0.6518724 ]\n"
     ]
    }
   ],
   "source": [
    "# re-train model 2 on balanced weights and \"unbiased\" data\n",
    "model6 = RandomForestClassifier(class_weight='balanced')\n",
    "model6.fit(x_train, y_train)\n",
    "y_pred = model6.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "model6accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "model6report = classification_report(y_test, y_pred)\n",
    "scores6 = cross_val_score(model6, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(scores6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4862b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6314330272049905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.86      0.72      3151\n",
      "           1       0.68      0.36      0.47      2620\n",
      "\n",
      "    accuracy                           0.63      5771\n",
      "   macro avg       0.65      0.61      0.59      5771\n",
      "weighted avg       0.64      0.63      0.60      5771\n",
      "\n",
      "[0.63825364 0.63894664 0.60706861 0.64726265 0.63661581]\n"
     ]
    }
   ],
   "source": [
    "# re-train model 1 on normal weights and \"unbiased\" data\n",
    "model7 = LogisticRegression()\n",
    "model7.fit(x_train, y_train)\n",
    "y_pred = model7.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "model7accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "model7report = classification_report(y_test, y_pred)\n",
    "scores7 = cross_val_score(model7, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(scores7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1c84bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6236354184716687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.81      0.70      3151\n",
      "           1       0.63      0.40      0.49      2620\n",
      "\n",
      "    accuracy                           0.62      5771\n",
      "   macro avg       0.63      0.61      0.60      5771\n",
      "weighted avg       0.63      0.62      0.61      5771\n",
      "\n",
      "[0.65142065 0.63825364 0.60984061 0.65627166 0.64979196]\n"
     ]
    }
   ],
   "source": [
    "# re-train model 2 on normal weights and \"unbiased\" data\n",
    "model8 = RandomForestClassifier()\n",
    "model8.fit(x_train, y_train)\n",
    "y_pred = model8.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "model8accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "model8report = classification_report(y_test, y_pred)\n",
    "scores8 = cross_val_score(model8, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(scores8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ac33250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the results to output.txt\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(f\"Model 1 (biased and balanced):\\n\")\n",
    "    f.write(f\"Accuracy: {model1accuracy}\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(model1report)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Cross validation scores: {scores1}\\n\\n\")\n",
    "    f.write(\"Model 2 (biased and balanced):\\n\")\n",
    "    f.write(f\"Accuracy: {model2accuracy}\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(model2report)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Cross validation scores: {scores2}\\n\\n\")\n",
    "    f.write(f\"Model 3 (1 but biased and unbalanced):\\n\")\n",
    "    f.write(f\"Accuracy: {model3accuracy}\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(model3report)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Cross validation scores: {scores3}\\n\\n\")\n",
    "    f.write(\"Model 4 (2 but biased and unbalanced):\\n\")\n",
    "    f.write(f\"Accuracy: {model4accuracy}\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(model4report)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Cross validation scores: {scores4}\\n\\n\")\n",
    "    f.write(f\"Model 5 (1 but unbiased and balanced):\\n\")\n",
    "    f.write(f\"Accuracy: {model5accuracy}\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(model5report)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Cross validation scores: {scores5}\\n\\n\")\n",
    "    f.write(\"Model 6 (2 but unbiased and balanced):\\n\")\n",
    "    f.write(f\"Accuracy: {model6accuracy}\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(model6report)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Cross validation scores: {scores6}\\n\\n\")\n",
    "    f.write(f\"Model 7 (1 but unbiased and unbalanced):\\n\")\n",
    "    f.write(f\"Accuracy: {model7accuracy}\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(model7report)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Cross validation scores: {scores7}\\n\\n\")\n",
    "    f.write(\"Model 8 (2 but unbiased and unbalanced):\\n\")\n",
    "    f.write(f\"Accuracy: {model8accuracy}\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(model8report)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"Cross validation scores: {scores8}\\n\\n\")\n",
    "    f.write(f\"Average accuracy of models 1 and 2: {(model1accuracy + model2accuracy) / 2}\\n\")\n",
    "    f.write(f\"Average accuracy of models 3 and 4: {(model3accuracy + model4accuracy) / 2}\\n\")\n",
    "    f.write(f\"Average accuracy of models 5 and 6: {(model5accuracy + model6accuracy) / 2}\\n\")\n",
    "    f.write(f\"Average accuracy of models 7 and 8: {(model7accuracy + model8accuracy) / 2}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
